# NPF Vanilla VMv4.5 2024101801
#version=RHEL9
# Use text mode install
text
#repo --name="AppStream" --baseurl=file:///run/install/sources/mount-0000-cdrom/AppStream
repo --name="AppStream" --baseurl=file:///run/install/repo/AppStream

# Commented since we don't have internet for sure
#repo --name=epel --baseurl=https://dl.fedoraproject.org/pub/epel/9/Everything/x86_64/ --install
%addon com_redhat_kdump --disable
%end

%pre --interpreter=/bin/python3
#! /usr/bin/env python3
#  -*- coding: utf-8 -*-


__intname__ = "kickstart.partition_script.RHEL9"
__author__ = "Orsiris de Jong"
__copyright__ = "Copyright (C) 2022-2024 Orsiris de Jong - NetInvent SASU"
__licence__ = "BSD 3-Clause"
__build__ = "2024101301"

### This is a pre-script for kickstart files in RHEL 9
### Allows specific partition schemes with one or more data partitions
# Standard paritioning scheme is
# | (efi) | boot | root | data 1 | data part n | swap
# LVM partitioning scheme is
# | (efi) | boot | lv [data 1| data part n | swap]

# Please note that the following arguments can be superseeded by kernel arguments
# TARGET, USER_NAME, USER_PASSWORD, ROOT_PASSWORD, HOSTNAME, DISK_PATH
# You need to specify that kernel argument as NPF_{ARGUMENT_NAME}=value, example
# append initrd=initrd.img inst.ks=hd:LABEL=MYDISK:/ks.rhel9.cfg NPF_USER_NAME=bob

## Possible partitionning targets
# generic: One big root partition
# web: Generic web server setup
# anssi: ANSSI-BP028 high profile compatible partitioning scheme
# hv: Standard KVM hypervisor
# hv-stateless: Stateless KVM hypervisor, /!\: NOT LVM compatible
# stateless: Generic machine with a 50% sized partition for statefulness (readonly-ro), /!\: NOT LVM compatible
TARGET = "anssi"

# Reserve 5% of disk space on physical machines, useful for SSD disks
# Set to 0 to disable
REDUCE_PHYSICAL_DISK_SPACE = 5

# Enable LVM partitioning (if using stateless partition profiles, this will be automatically disabled)
LVM_ENABLED = True
# LVM volume group name
VG_NAME = "vg00"
# LVM Physical extent size
PE_SIZE = 4096

## Password management
# You can use plaintext password, or set IS_ROOT_PASSWORD_CRYPTED or IS_USER_PASSWORD_CRYPTED
# In the latter case, you'll need to use a password generated using `openssl passwd -6 SomePassword`
IS_ROOT_PASSWORD_CRYPTED = True
# The following password is the output of openssl passwd -6 MySuperSecretPWD123!
ROOT_PASSWORD = r"$6$mvkdq9kR615kyHcd$XXrHM9.rdOvzECyupe1q/JEWqgLJm8i6oGN3RqruBAG1RfHwqHe0x9poQm5NbM21jFNoEIHIgPZmBE4nYsgoJ1"

USER_NAME = "myuser"
IS_USER_PASSWORD_CRYPTED = True
# The following password is the output of openssl passwd -6 MySecretPWD123!
USER_PASSWORD = r"$6$ptVdrpI1pqmpTy/Y$8/D4oJbofV4ZsyZ1hSXn.biyw6fDA9qozGXK3B0lXB5c39XJ.tlzv5v5Hedx7cI1uLPrVlB.Ua6n4mk/iYgcN0"

## Hostname
HOSTNAME = "machine.npf.local"

## Package management
# Add lm-sensros and smartmontools on physical machines
ADD_PHYSICAL_PACKAGES = True
# Remove firmware packages, plymouth and pipewire on virtual machines
REMOVE_VIRTUAL_PACKAGES = True

### Set Partition schema here
# boot and swap partitions are automatically created
# Sizes can be
# - <nn>: Size in MiB (eg IEC bytes, where 1MiB = 1024KiB = 1048576 bytes)
# - <nn%>: Percentage of remaining size after fixed size has been allocated
# - True: Fill up remaining space after fixed and percentage size has been allocated
#         If multiple True values exist, we'll divide by percentages of remaining space

# Partition schema for standard KVM Hypervisor
PARTS_HV = [
    {"size": 30720, "fs": "xfs", "mountpoint": "/"},
    {"size": True, "fs": "xfs", "mountpoint": "/var/lib/libvirt/images", "fsoptions": "nodev,nosuid,noexec"},
]

# Partition schema for stateless KVM Hypervisor
PARTS_HV_STATELESS = [
    {"size": 30720, "fs": "xfs", "mountpoint": "/"},
    {"size": True, "fs": "xfs", "mountpoint": "/var/lib/libvirt/images", "fsoptions": "nodev,nosuid,noexec"},
    {"size": 30720, "fs": "xfs", "mountpoint": None, "label": "STATEFULRW"},
]

# Partition schema for stateless machines
PARTS_STATELSSS = [
    {"size": True, "fs": "xfs", "mountpoint": "/"},
    {"size": True, "fs": "xfs", "mountpoint": None, "label": "STATEFULRW"},
]

# Partition schema for generic machines with only one big root partition
PARTS_GENERIC = [
    {"size": True, "fs": "xfs", "mountpoint": "/"}
]

# Partition schema for generic web servers (sized for minimum 20GiB web servers)
PARTS_WEB = [
    {"size": 5120, "fs": "xfs", "mountpoint": "/"},
    {"size": True, "fs": "xfs", "mountpoint": "/var/www", "fsoptions": "nodev,nosuid,noexec"},
    {"size": 4096, "fs": "xfs", "mountpoint": "/var/log", "fsoptions": "nodev,nosuid,noexec"},
    {"size": 1024, "fs": "xfs", "mountpoint": "/tmp", "fsoptions": "nodev,nosuid,noexec"},
    {"size": 1024, "fs": "xfs", "mountpoint": "/var/tmp", "fsoptions": "nodev,nosuid,noexec"},
]

# Example partition schema for ANSSI-BP028 high profile
# This example requires at least 65GiB of disk space
# as it will also require swap space depeding on memory size, /boot and /boot/efi space
PARTS_ANSSI = [
    {"size": 5120, "fs": "xfs", "mountpoint": "/"},
    {"size": 5120, "fs": "xfs", "mountpoint": "/usr", "fsoptions": "nodev"},
    {"size": 1024, "fs": "xfs", "mountpoint": "/opt", "fsoptions": "nodev,nosuid"},
    {"size": 10240, "fs": "xfs", "mountpoint": "/home", "fsoptions": "nodev"},
    # {"size": 40960 , "fs": "xfs", "mountpoint": "/srv", "fsoptions": "nodev,nosuid"},        # When FTP/SFTP server is used
    {"size": 5120, "fs": "xfs", "mountpoint": "/tmp", "fsoptions": "nodev,nosuid,noexec"},
    {"size": True, "fs": "xfs", "mountpoint": "/var", "fsoptions": "nodev"},
    {"size": 5120, "fs": "xfs", "mountpoint": "/var/tmp", "fsoptions": "nodev,nosuid,noexec"},
    {"size": 10240, "fs": "xfs", "mountpoint": "/var/log", "fsoptions": "nodev,nosuid,noexec"},
    {"size": 2048, "fs": "xfs", "mountpoint": "/var/log/audit", "fsoptions": "nodev,nosuid,noexec"},
]

#################################################################
# DO NOT MODIFY BELOW THIS LINE UNLESS YOU KNOW WHAT YOU'RE DOING
#################################################################


import sys
import os
from typing import Tuple, Optional
import subprocess
import logging
from time import sleep


def dirty_cmd_runner(cmd: str) -> Tuple[int, str]:
    """
    QaD command runner
    """
    try:
        result = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
        return True, result.decode("utf-8")
    except subprocess.CalledProcessError as exc:
        result = exc.output
        return False, result
    

def get_kernel_arguments() -> dict:
    """
    Retrieve additional kernel arguments
    """
    def _get_kernel_argument(argument_name: str) -> Optional[str]:
        """
        Retrieve a kernel argument
        """

        cmd=rf"grep -oi '{argument_name}=\S*' /proc/cmdline | cut -d '=' -f 2"
        result, output = dirty_cmd_runner(cmd)
        if result:
            argument_value = output.split("\n")[0].strip()
            if argument_value:
                logger.info(f"Found kernel argument {argument_name}={argument_value}")
                return argument_value
        return None
    
    argument_list = [
        "TARGET", "USER_NAME", "USER_PASSWORD", "ROOT_PASSWORD", "HOSTNAME", "DISK_PATH"
    ]

    kernel_arguments = {}

    for argument in argument_list:
        argument_name = f"NPF_{argument}"
        argument_value = _get_kernel_argument(argument_name)
        if argument_value:
            kernel_arguments[argument] = argument_value
    return kernel_arguments


def is_gpt_system() -> bool:
    if DEV_MOCK:
        return True
    is_gpt = os.path.exists("/sys/firmware/efi")
    if is_gpt:
        logger.info("We're running on a UEFI machine")
    else:
        logger.info("We're running on a MBR machine")
    return is_gpt


def get_mem_size() -> int:
    """
    Returns memory size in MiB
    Balantly copied from https://stackoverflow.com/a/28161352/2635443
    """
    if DEV_MOCK:
        return 16384
    mem_bytes = os.sysconf("SC_PAGE_SIZE") * os.sysconf(
        "SC_PHYS_PAGES"
    )  # e.g. 4015976448
    mem_mib = int(mem_bytes / (1024.0**2))  # e.g. 16384
    logger.info(f"Current system has {mem_mib} MiB of memory")
    return mem_mib


def get_first_disk_path() -> list:
    """
    Return list of disks

    First, let's get the all the available disk names (ex hda,sda,vda)
    We might have a /dev/zram0 device which is considered as disk, so we need to filter vdX,sdX,hdX
    """
    if DEV_MOCK:
        return "/dev/vdx"
    # -I only include disk types 8 = hard disk, 252 = vdisk, 259 = nvme disk
    # -ndp -n no headers, -d only devices (no partitions), -p show full path
    # --output NAME,TYPE,HOTPLUG only output name and type
    # awk will filter by non hotplug devices and return a line per disk
    cmd = r"lsblk -I 8,252,259 -ndp --output HOTPLUG,NAME | awk '{ if ($1 == 0) { print $2 }}'"
    result, output = dirty_cmd_runner(cmd)
    if result:
        disk_path = output.split("\n")[0].strip()
        logger.info(f"First usable disk is {disk_path}")
        return disk_path

    logger.error(f"Cannot find usable disk: {output}")
    return False


def zero_disk(disk_path: str) -> bool:
    """
    Zero first disk bytes
    We need this instead of "cleanpart" directive since we're partitionning manually
    in order to have a custom partition schema
    We'll also wipe partitions and then the partition table
    """
    cmd = f"dd if=/dev/zero of={disk_path} bs=512 count=1 conv=notrunc; wipefs -a {disk_path}[0-9] -f; wipefs -a {disk_path} -f"
    logger.info(f"Zeroing disk {disk_path}")
    if DEV_MOCK:
        return True
    result, output = dirty_cmd_runner(cmd)
    if not result:
        logger.error(f"Could not zero disk {disk_path}:\n{output}")

    # blockdev -rereadpt works better than partprobe
    # see https://serverfault.com/questions/749258/how-to-reset-a-harddisk-delete-mbr-delete-partitions-from-the-command-line-w
    cmd = f"blockdev --rereadpt {disk_path}"
    logger.info("Reloading partition table")
    result, output = dirty_cmd_runner(cmd)
    if not result:
        logger.error(f"Could not reload partition table:\n{output}")
    return result


def init_disk(disk_path: str) -> bool:
    """
    Create disk label
    """
    if IS_GPT:
        label = "gpt"
    else:
        label = "msdos"
    cmd = f"parted -s {disk_path} mklabel {label}"
    logger.info(f"Making {disk_path} label")
    if DEV_MOCK:
        return True
    result, output = dirty_cmd_runner(cmd)
    if not result:
        logger.error(f"Could not make {disk_path} label: {output}")
    return result


def get_disk_size_mb(disk_path: str) -> int:
    """
    Get disk size in megabytes
    Use parted so we don't rely on other libs
    """
    if DEV_MOCK:
        return 61140  # 60GiB
    cmd = f"parted -s {disk_path} unit mib print | grep {disk_path} | awk '{{ print $3 }}' | cut -d'M' -f1"
    logger.info(f"Getting {disk_path} size")
    result, output = dirty_cmd_runner(cmd)
    if result:
        try:
            disk_size = int(output)
            logger.info(f"Disk {disk_path} size is {disk_size} MiB")
            return disk_size
        except Exception as exc:
            logger.error(f"Cannot get {disk_path} size: {exc}. Result was {output}")
            return False
    else:
        logger.error(f"Cannot get {disk_path} size. Result was {output}")
        return False


def get_allocated_space(partitions_schema: dict) -> int:
    # Let's fill ROOT part with anything we can
    allocated_space = 0
    for key, value in partitions_schema.items():
        if key == "lvm":
            for lvm_value in value.values():
                allocated_space += lvm_value["size"]
            continue
        allocated_space += partitions_schema[key]["size"]
    return allocated_space


def get_partition_schema(selected_partition_schema: dict) -> dict:
    """
    Return a valid partition schema dict to apply with sizes and mountpoints, generated from the selected partition schema dict
    """

    mem_size = get_mem_size()
    # Swap size will be at least 1446MiB since RHEL9 will require at least 3GiB (minus crash kernel) to install
    if mem_size > 16384:
        swap_size = mem_size
    else:
        swap_size = int(mem_size / 2)

    def create_partition_schema():
        if IS_GPT:
            partitions_schema = {
                "0": {"size": 600, "fs": "fat32", "mountpoint": "/boot/efi"},
                "1": {"size": 1024, "fs": "xfs", "mountpoint": "/boot"},
            }
        else:
            partitions_schema = {
                "0": {"size": 1024, "fs": "xfs", "mountpoint": "/boot"}
            }

        if LVM_ENABLED:
            partitions_schema["lvm"] = {
                "99": {"size": swap_size, "fs": "linux-swap", "mountpoint": "swap"}
            }
        else:
            partitions_schema["99"] = {
                "size": swap_size,
                "fs": "linux-swap",
                "mountpoint": "swap",
            }
        return partitions_schema

    def add_fixed_size_partitions(partitions_schema):
        """
        Add fixed size partitions to partition schema
        """
        for index, partition in enumerate(selected_partition_schema):
            # Shift index so we don't overwrite boot partition indexes
            index = str(int(index) + 10)
            if not isinstance(partition["size"], bool) and isinstance(
                partition["size"], int
            ):
                if LVM_ENABLED:
                    partitions_schema["lvm"][index] = {"size": partition["size"]}
                else:
                    partitions_schema[index] = {"size": partition["size"]}
        return partitions_schema

    def add_percent_size_partitions(partitions_schema):
        """
        Add percentage size partitions to partition schema
        """
        total_percentage = 0
        free_space = USABLE_DISK_SPACE - get_allocated_space(partitions_schema)
        for index, partition in enumerate(selected_partition_schema):
            index = str(int(index) + 10)
            if isinstance(partition["size"], str) and partition["size"][-1] == "%":
                percentage = int(partition["size"][:-1])
                total_percentage += percentage
                size = int(free_space * percentage / 100)
                if LVM_ENABLED:
                    partitions_schema["lvm"][index] = {"size": size}
                else:
                    partitions_schema[index] = {"size": size}
        if total_percentage > 100:
            msg = f"Percentages add up to more than 100%: {total_percentage}"
            logger.error(msg)
            return False
        return partitions_schema

    def get_number_of_filler_parts():
        """
        Determine the number of partitions that will fill the remaining space
        """
        filler_parts = 0
        for partition in selected_partition_schema:
            if isinstance(partition["size"], bool):
                filler_parts += 1
        return filler_parts

    def populate_partition_schema_with_other_data(partitions_schema):
        """
        Populate partition schema with FS and mountpoints
        """
        for index, partition in enumerate(selected_partition_schema):
            index = str(int(index + 10))
            for key, value in partition.items():
                if key == "size":
                    continue
                try:
                    if LVM_ENABLED:
                        partitions_schema["lvm"][index][key] = value
                    else:
                        partitions_schema[index][key] = value
                except KeyError:
                    pass
        return partitions_schema

    ## FN ENTRY POINT
    # MBR can have max 4 primary partitions, can't be bothered to code this in 2024
    if len(selected_partition_schema) >= 3 and not IS_GPT and not LVM_ENABLED:
        logger.error(
            "We cannot create more than 4 parts in MBR mode (boot + swap + two other partitions)...Didn't bother to code that path for prehistoric systems. Consider enabling LVM"
        )
        sys.exit(1)

    # Create a basic partition schema
    partitions_schema = create_partition_schema()
    # Add fixed size partitions to partition schema
    partitions_schema = add_fixed_size_partitions(partitions_schema)
    # Add percentage size partitions to partition schema
    partitions_schema = add_percent_size_partitions(partitions_schema)

    filler_parts = get_number_of_filler_parts()
    logger.info(f"Number of filler partitions: {filler_parts}")
    # Depending on how many partitions fill the remaining space, convert filler partitions to percentages
    if filler_parts > 1:
        for index, partition in enumerate(selected_partition_schema):
            # If we already have percentage partitions, we need to drop them now
            if isinstance(partition["size"], str) and partition["size"][-1] == "%":
                selected_partition_schema[index]["size"] = "already calculated"
            if isinstance(partition["size"], bool):
                selected_partition_schema[index]["size"] = str(int(100 / filler_parts)) + "%"
        # Now we have to do the percentage calculations again
        partitions_schema = add_percent_size_partitions(partitions_schema)
    else:
        # Else just fill remaining partition with all space
        free_space = USABLE_DISK_SPACE - get_allocated_space(partitions_schema)
        if free_space < 0:
            logger.error(
                "Cannot fill remaining space with partitions. Not enough space left. Is your partition schema valid ?"
            )
            logger.error(
                f"Usable disk space: {USABLE_DISK_SPACE}, schema allocated space: {get_allocated_space(partitions_schema)}"
            )
            sys.exit(1)
        for index, partition in enumerate(selected_partition_schema):
            index = str(int(index + 10))
            if isinstance(partition["size"], bool):
                if LVM_ENABLED:
                    partitions_schema["lvm"][index] = {"size": free_space}
                else:
                    partitions_schema[index] = {"size": free_space}
    partitions_schema = populate_partition_schema_with_other_data(partitions_schema)

    # Sort partition schema
    partitions_schema = dict(sorted(partitions_schema.items()))
    if LVM_ENABLED:
        partitions_schema["lvm"] = dict(sorted(partitions_schema["lvm"].items()))
    return partitions_schema


def validate_partition_schema(partitions: dict) -> bool:
    """
    Check if our partition schema doesn't exceeed disk size
    """
    total_size = 0
    for partition in partitions.keys():
        if partition == "lvm":
            for lvm_partition in partitions["lvm"].keys():
                for key, value in partitions["lvm"][lvm_partition].items():
                    if key == "size":
                        total_size += value
                msg = f"LVMPART {lvm_partition}: {partitions[partition][lvm_partition]}"
                logger.info(msg)
            continue
        for key, value in partitions[partition].items():
            if key == "size":
                total_size += value
        msg = f"PART {partition}: {partitions[partition]}"
        logger.info(msg)

    if total_size > USABLE_DISK_SPACE:
        msg = f"Total required partition space {total_size} exceeds disk space {USABLE_DISK_SPACE}"
        logger.error(msg)
        return False
    logger.info(f"Total allocated disk size: {total_size} / {USABLE_DISK_SPACE}")
    return True


def prepare_non_kickstart_partitions(partitions_schema: dict) -> bool:
    """
    When partitions don't have a mountpoint, we'll have to create the FS ourselves
    If partition has a xfs label, let's create it
    """

    def prepare_non_kickstart_partition(part_properties, part_number):
        if part_properties["mountpoint"] is None:
            logger.info(
                f"Partition {DISK_PATH}{part_number} has no mountpoint and won't be handled by kickstart. Going to create it FS {part_properties['fs']}"
            )
            cmd = f'mkfs.{part_properties["fs"]} -f {DISK_PATH}{part_number}'
            if DEV_MOCK:
                result = True
            else:
                result, output = dirty_cmd_runner(cmd)
            if not result:
                logger.error(f"Command {cmd} failed: {output}")
                return False

        if "label" in part_properties.keys():
            if part_properties["fs"] == "xfs":
                cmd = (
                    f'xfs_admin -L {part_properties["label"]} {DISK_PATH}{part_number}'
                )
            elif part_properties["fs"].lower()[:3] == "ext":
                cmd = f'tune2fs -L {part_properties["label"]} {DISK_PATH}{part_number}'
            else:
                logger.error(
                    f'Setting label on FS {part_properties["fs"]} is not implemented'
                )
                return False
            logger.info(
                f'Setting up partition {DISK_PATH}{part_number} FS {part_properties["fs"]} with label {part_properties["label"]}'
            )
            if DEV_MOCK:
                result = True
            else:
                result, output = dirty_cmd_runner(cmd)
            if not result:
                logger.error(f"Command {cmd} failed: {output}")
                return False
        return True

    part_number = 1
    for part_index, part_properties in partitions_schema.items():
        if part_index == "lvm":
            for lvm_part_properties in partitions_schema["lvm"].values():
                prepare_non_kickstart_partition(lvm_part_properties, part_number)
        else:
            prepare_non_kickstart_partition(part_properties, part_number)
        part_number += 1
    return True


def write_kickstart_partitions_file(partitions_schema: dict) -> bool:
    part_number = 1
    kickstart = ""
    for key, part_properties in partitions_schema.items():
        if key == "lvm":
            kickstart += f"part pv.0 --fstype lvmpv --grow --size=1\n"
            kickstart += f"volgroup {VG_NAME} pv.0 --pesize={PE_SIZE}\n"
            part_number += 1
            continue
        if part_properties["mountpoint"]:
            # parted wants "linux-swap" whereas kickstart needs "swap" as fstype
            if part_properties["fs"] == "linux-swap":
                part_properties["fs"] = "swap"
            try:
                fsoptions = f' --fsoptions={part_properties["fsoptions"]}'
            except KeyError:
                # Don't bother if partition doesn't have fsoptions
                fsoptions = ""
            kickstart += f'part {part_properties["mountpoint"]} --fstype {part_properties["fs"]} --onpart={DISK_PATH}{part_number}{fsoptions}\n'
        part_number += 1

    if LVM_ENABLED:
        for part_properties in partitions_schema["lvm"].values():
            if part_properties["mountpoint"]:
                # parted wants "linux-swap" whereas kickstart needs "swap" as fstype
                if part_properties["fs"] == "linux-swap":
                    part_properties["fs"] = "swap"
                try:
                    fsoptions = f' --fsoptions={part_properties["fsoptions"]}'
                except KeyError:
                    # Don't bother if partition doesn't have fsoptions
                    fsoptions = ""
                if part_properties["mountpoint"] == "/":
                    name = "root"
                else:
                    name = part_properties["mountpoint"].replace("/", "")
                kickstart += f'logvol {part_properties["mountpoint"]} --vgname {VG_NAME} --fstype {part_properties["fs"]} --name={name}{fsoptions} --size={part_properties["size"]}\n'
            part_number += 1
    try:
        with open("/tmp/partitions", "w", encoding="utf-8") as fp:
            fp.write(kickstart)
    except OSError as exc:
        logger.error(f"Cannot write /tmp/partitions: {exc}")
        return False
    return True


def execute_parted_commands(partitions_schema: dict) -> bool:
    """
    We need to manually run partitioning commands since we're not using anaconda to create partitions
    This allows us to have non mounted partitions, eg stateful partitions for readonly-root setups

    Unless specified, parted deals in megabytes
    """
    parted_commands = []
    partition_start = 0
    for part_index, part_properties in partitions_schema.items():
        if partition_start == 0:
            # Properly align first partition to 1MiB for SSD disks
            partition_start = "1024KiB"
            partition_end = 1 + part_properties["size"]

        elif part_index == "lvm":
            # Assume we only have one big lvm partition, don't bother with others
            # Also, we don't need to create it via parted, since this is automagically done by anaconda
            continue

        else:  # Non LVM partitions handling
            partition_start = partition_end
            partition_end = partition_start + part_properties["size"]
        parted_commands.append(
            f'parted -a optimal -s {DISK_PATH} mkpart primary {part_properties["fs"]} {partition_start} {partition_end}'
        )
    for parted_command in parted_commands:
        if DEV_MOCK:
            logger.info(f"Would execute command {parted_command}")
            result = True
        else:
            logger.info(f"Executing command {parted_command}")
            result, output = dirty_cmd_runner(parted_command)
        if not result:
            logger.error(f"Command failed: {output}")
            return False
    # Arbitrary sleep command
    sleep(3)
    return True


def setup_package_lists() -> bool:
    logger.info("Setting up package ignore lists")
    package_ignore_virt_list = [
        "linux-firmware",
        "a*-firmware",
        "i*-firmware",
        "lib*firmware",
        "n*firmware",
        "plymouth",
        "pipewire",
    ]

    package_add_physical_list = ["lm_sensors", "smartmontools"]
    try:
        with open("/tmp/packages", "w", encoding="utf-8") as fp:
            if IS_VIRTUAL and REMOVE_VIRTUAL_PACKAGES:
                for package in package_ignore_virt_list:
                    fp.write(f"-{package}\n")
            elif not IS_VIRTUAL and ADD_PHYSICAL_PACKAGES:
                for package in package_add_physical_list:
                    fp.write(f"{package}\n")
            else:
                fp.write("\n")
        return True
    except OSError as exc:
        logger.error(f"Cannot create /tmp/packages file: {exc}")
        return False


def setup_hostname(hostname: str = None) -> bool:
    logger.info("Setting up hostname")
    try:
        with open("/tmp/hostname", "w", encoding="utf-8") as fp:
            fp.write(f"network --hostname={hostname}\n")
        return True
    except OSError as exc:
        logger.error(f"Cannot create /tmp/hostname file: {exc}")
        return False


def setup_users() -> bool:
    """
    Root password non encrypted version
    rootpw MyNonEncryptedPassword
    user --name=user --password=MyNonEncryptedUserPassword

    Or password with encryption
    password SHA-512 with openssl passwd -6 (used here)
    password SHA-256 with openssl passwd -5
    password MD5 (don't) with openssl passwd -1
    rootpw --isencrypted <somestring>
    user --name user --isencrypted --password=<somestring>
    """
    logger.info("Setting up password file")
    if IS_ROOT_PASSWORD_CRYPTED:
        is_crypted = "--iscrypted "
    else:
        is_crypted = ""
    root = rf"rootpw {is_crypted}{ROOT_PASSWORD}"
    if IS_USER_PASSWORD_CRYPTED:
        is_crypted = "--iscrypted "
    else:
        is_crypted = ""
    user = rf"user --name {USER_NAME} {is_crypted}--password={USER_PASSWORD}"

    try:
        with open("/tmp/users", "w", encoding="utf-8") as fp:
            fp.write(f"{root}\n{user}\n")
        return True
    except OSError as exc:
        logger.error(f"Cannot create /tmp/users file: {exc}")
        return False


######################
# SCRIPT ENTRY POINT #
######################
# Set DEV_MOCK to True to avoid executing any command and just create the required files for anaconda
# Of course, we won't be able to get disk size and memory size
DEV_MOCK = False

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.FileHandler("/tmp/prescript.log"), logging.StreamHandler()],
)
logger = logging.getLogger()

if DEV_MOCK:
    logger.info(
        "Running in DEV_MOCK mode. Nothing will be executed or actually done here."
    )

TARGET = TARGET.lower()
DISK_PATH = get_first_disk_path()

# Superseed 
kernel_arguments = get_kernel_arguments()
for argument_name, argument_value in kernel_arguments.items():
    logger.info(f"Superseeding value {argument_name}={argument_value}")
    # Special case when superseeding passwords
    if argument_name == "ROOT_PASSWORD":
        IS_ROOT_PASSWORD_CRYPTED = False
    if argument_name == "USER_NAME":
        IS_USER_PASSWORD_CRYPTED = False
    globals()[argument_name] = argument_value


if TARGET in ["stateless", "hv-stateless"] and LVM_ENABLED:
    logger.info("Stateless machines are not compatible with LVM. Disabling LVM.")
    LVM_ENABLED = False

PARTS = None
if TARGET == "hv":
    PARTS = PARTS_HV
elif TARGET == "hv-stateless":
    PARTS = PARTS_HV_STATELESS
elif TARGET == "stateless":
    PARTS = PARTS_STATELSSS
elif TARGET == "generic":
    PARTS = PARTS_GENERIC
elif TARGET == "web":
    PARTS = PARTS_WEB
elif TARGET == "anssi":
    PARTS = PARTS_ANSSI
else:
    logger.error(f"Bad target given: {TARGET}")
    sys.exit(222)
logger.info(f"Running script for target: {TARGET}")


IS_VIRTUAL, _ = dirty_cmd_runner(
    r'dmidecode | grep -i "kvm\|qemu\|vmware\|hyper-v\|virtualbox\|innotek\|netperfect_vm"'
)
IS_GPT = is_gpt_system()

if not DISK_PATH:
    sys.exit(10)
if not zero_disk(DISK_PATH):
    sys.exit(1)
if not init_disk(DISK_PATH):
    sys.exit(2)
disk_space_mb = get_disk_size_mb(DISK_PATH)
if not disk_space_mb:
    sys.exit(3)
USABLE_DISK_SPACE = disk_space_mb - 2  # keep 1KiB empty at beginning and 1MiB at end
if not IS_VIRTUAL and REDUCE_PHYSICAL_DISK_SPACE:
    # Let's reserve 5% of disk space on physical machine
    REAL_USABLE_DISK_SPACE = USABLE_DISK_SPACE
    USABLE_DISK_SPACE = int(
        USABLE_DISK_SPACE * (100 - REDUCE_PHYSICAL_DISK_SPACE) / 100
    )
    logger.info(
        f"Reducing usable disk space by {REDUCE_PHYSICAL_DISK_SPACE}% from {REAL_USABLE_DISK_SPACE} to {USABLE_DISK_SPACE} since we deal with physical disks"
    )

partitions_schema = get_partition_schema(PARTS)
if not partitions_schema:
    sys.exit(4)
if not validate_partition_schema(partitions_schema):
    sys.exit(5)
if not execute_parted_commands(partitions_schema):
    sys.exit(6)
if not prepare_non_kickstart_partitions(partitions_schema):
    sys.exit(7)
if not write_kickstart_partitions_file(partitions_schema):
    sys.exit(8)

logger.info("Partitionning done. Please use '%include /tmp/partitions")

if not setup_package_lists():
    sys.exit(9)

if not setup_hostname(HOSTNAME):
    sys.exit(10)

if not setup_users():
    sys.exit(11)
%end

# System language
lang fr_FR.UTF-8

# Network information
network  --bootproto=dhcp --activate --onboot=yes

%include /tmp/hostname

# Use CDROM installation media
cdrom

%packages
@^minimal-environment
nano
iotop
qemu-guest-agent
policycoreutils-python-utils
tar
bind-utils
sysstat
tuned
dnf-automatic
# required since ANSSI profile configures rsyslogd to send logs to 'logcollector' fqdn entry with TLS
rsyslog-gnutls

# Non included in minimal, hence we need internet configured right or at least a non minimal cd
#xterm-resize # replaced with /etc/profile.d/term_resize.sh hack

# EPEL dependant (will be installed in postscript)
#atop
#nmon
#iptraf
#iftop

# Security
openscap
scap-security-guide

%include /tmp/packages
%end

# Run the Setup Agent on first boot
firstboot --enable
# Do not configure the X Window System
skipx

%include /tmp/partitions

timesource --ntp-server=0.fr.pool.ntp.org
# System timezone
timezone Europe/Paris --utc

# keyboard
keyboard fr
selinux --enforcing
firewall --enabled --service ssh
lang C.UTF-8

%include /tmp/users
%post
#!/usr/bin/env bash

# SCRIPT BUILD 2024101801

LOG_FILE=/root/.npf-postinstall.log
POST_INSTALL_SCRIPT_GOOD=true

function log {
    local log_line="${1}"
    local level="${2}"

    echo "${log_line}" >> "${LOG_FILE}"
    echo "${log_line}"

    if [ "${level}" == "ERROR" ]; then
        POST_INSTALL_SCRIPT_GOOD=false
    fi
}

log "Starting NPF post install at $(date)"

# This is a duplicate from the Python script, but since we don't inherit pre settings, we need to redeclare it
# Physical machine can return
# VME (Virtual mode extension)
# Enhanced Virtualization

# Hence we need to detect specific products
if ! type -p dmidecode > /dev/null 2>&1; then
    log "dmidecode not found, trying to install it"
    dnf install -y dmidecode
fi
if ! type -p dmidecode > /dev/null 2>&1; then
    log "Cannot find dmidecode, let's assume this is a physical machine" "ERROR"
    IS_VIRTUAL=false
else
    dmidecode | grep -i "kvm\|qemu\|vmware\|hyper-v\|virtualbox\|innotek\|netperfect_vm" > /dev/null 2>&1
    if [ $? -eq 0 ]; then
        IS_VIRTUAL=true
    else
        IS_VIRTUAL=false
    fi
fi



# We need a dns hostname in order to validate that we got internet before using internet related functions
# Also, we need to make sure 
function check_internet {
    fqdn_host="one.one.one.one kernel.org github.com"
    ip_hosts="2606:4700:4700::1001 8.8.8.8 9.9.9.9"
    for host in ${fqdn_host[@]}; do
        ping -6 -c2 "${host}" > /dev/null 2>&1
        if [ $? -eq 0 ]; then
            log "FQDN IPv6 echo request to ${host} works."
            return 0
        else
            log "FQDN IPv6 echo request to ${host} failed."
        fi
        ping -4 -c2 "${host}" > /dev/null 2>&1
        if [ $? -eq 0 ]; then
            log "FQDN IPv4 echo request to ${host} works."
            return 0
        else
            log "FQDN IPv4 echo request to ${host} failed."
        fi
    done
    log "Looks like we cannot access internet via hostnames. Let's try IPs"
    for host in ${ip_hosts[@]}; do
        ping -c2 "${host}" > /dev/null 2>&1
        if [ $? -eq 0 ]; then
            log "IP check to ${host} works."
            return 1
        fi
    done
    ip_result=$(ip a)
    route_result=$(ip route)
    resolv=$(cat /etc/resolv.conf)
    log "Internet check failed. Please find output of diag commands:" "NOTICE"
    log "ip a:\n${ip_result}\n\n"
    log "ip route:\n${route_result}\n\n"
    log "resolv.conf content:\n${resolv}\n\n"

    return 1
}

# NPF-MOD
if [ ${IS_VIRTUAL} == true ]; then
    NPF_NAME=VMv4.5
else
    NPF_NAME=PMv4.5
fi
cat << EOF > /etc/issue
NetPerfect $NPF_NAME

IPv4 \4
IPv6 \6

EOF

# Disable --fetch-remote-resources on machines without internet
[ ! -d /root/openscap_report ] && mkdir /root/openscap_report

check_internet
if [ $? -eq 0 ]; then
    # Let's reinstall openscap in case we're running this script on a non prepared machine
    dnf install -y openscap scap-security-guide || log "OpenSCAP is missing and cannot be installed" "ERROR"
    log "Setting up scap profile with remote resources"
    oscap xccdf eval --profile anssi_bp28_high --fetch-remote-resources --remediate /usr/share/xml/scap/ssg/content/ssg-almalinux9-ds.xml > /root/openscap_report/actions.log 2>&1
    # result 2 is partially applied, which can be normal
    if [ $? -eq 1 ]; then
        log "OpenSCAP failed. See /root/openscap_report/actions.log" "ERROR"
    else
        log "Generating scap results with remote resources"
        oscap xccdf generate guide --fetch-remote-resources --profile anssi_bp28_high /usr/share/xml/scap/ssg/content/ssg-almalinux9-ds.xml > "/root/openscap_report/oscap_anssi_bp028_high_$(date '+%Y-%m-%d').html" 2>> "${LOG_FILE}"
        [ $? -ne 0 ] && log "OpenSCAP results failed. See log file" "ERROR"
    fi
else
    log "Setting up scap profile without internet"
    oscap xccdf eval --profile anssi_bp28_high --remediate /usr/share/xml/scap/ssg/content/ssg-almalinux9-ds.xml > /root/openscap_report/actions.log 2>&1
    if [ $? -eq 1 ]; then
        log "OpenSCAP failed. See /root/openscap_report/actions.log" "ERROR"
    else
        log "Generating scap results without internet"
        oscap xccdf generate guide --profile anssi_bp28_high /usr/share/xml/scap/ssg/content/ssg-almalinux9-ds.xml > "/root/openscap_report/oscap_anssi_bp028_high_$(date '+%Y-%m-%d').html" 2>> "${LOG_FILE}"
        [ $? -ne 0 ] && log "OpenSCAP results failed. See log file" "ERROR"
    fi
fi


# Fix firewall cannot load after anssi_bp28_high
setsebool -P secure_mode_insmod=off

# NPF don't fetch dnf epel packages since it's not sure we get internet
# Setup EPEL and packages
check_internet
if [ $? -eq 0 ]; then
    log "Install available with internet. setting up additional packages."
    dnf install -4 -y epel-release 2>> "${LOG_FILE}" || log "Failed to install epel-release" "ERROR"
    dnf install -4 -y htop atop nmon iftop iptraf 2>> "${LOG_FILE}" || log "Failed to install additional tools" "ERROR"
else
    log "No epel available without internet. Didn't install additional packages."
fi

if [ ${IS_VIRTUAL} != true ]; then
    log "Setting up disk SMART tooling"
    echo "DEVICESCAN -H -l error -f -C 197+ -U 198+ -t -l selftest -I 194 -n sleep,7,q -s (S/../.././10|L/../../[5]/13)" >> /etc/smartmontools/smartd.conf 
    systemctl enable smartd 2>> "${LOG_FILE}" || log "Failed to start smartd" "ERROR"

    log "Setting up smart script for prometheus"
    cat << 'EOF' > /usr/local/bin/smartmon.sh
#!/usr/bin/env bash
#
# Script informed by the collectd monitoring script for smartmontools (using smartctl)
# by Samuel B. <samuel_._behan_(at)_dob_._sk> (c) 2012
# source at: http://devel.dob.sk/collectd-scripts/

# TODO: This probably needs to be a little more complex.  The raw numbers can have more
#       data in them than you'd think.
#       http://arstechnica.com/civis/viewtopic.php?p=22062211

# Formatting done via shfmt -i 2
# https://github.com/mvdan/sh

# Ensure predictable numeric / date formats, etc.
export LC_ALL=C

parse_smartctl_attributes_awk="$(
    cat <<'SMARTCTLAWK'
$1 ~ /^ *[0-9]+$/ && $2 ~ /^[a-zA-Z0-9_-]+$/ {
    gsub(/-/, "_");
    printf "%s_value{%s,smart_id=\"%s\"} %d\n", $2, labels, $1, $4
    printf "%s_worst{%s,smart_id=\"%s\"} %d\n", $2, labels, $1, $5
    printf "%s_threshold{%s,smart_id=\"%s\"} %d\n", $2, labels, $1, $6
    printf "%s_raw_value{%s,smart_id=\"%s\"} %e\n", $2, labels, $1, $10
}
SMARTCTLAWK
)"

smartmon_attrs="$(
    cat <<'SMARTMONATTRS'
airflow_temperature_cel
command_timeout
current_pending_sector
end_to_end_error
erase_fail_count
g_sense_error_rate
hardware_ecc_recovered
host_reads_32mib
host_reads_mib
host_writes_32mib
host_writes_mib
load_cycle_count
media_wearout_indicator
nand_writes_1gib
offline_uncorrectable
power_cycle_count
power_on_hours
program_fail_cnt_total
program_fail_count
raw_read_error_rate
reallocated_event_count
reallocated_sector_ct
reported_uncorrect
runtime_bad_block
sata_downshift_count
seek_error_rate
spin_retry_count
spin_up_time
start_stop_count
temperature_case
temperature_celsius
temperature_internal
total_lbas_read
total_lbas_written
udma_crc_error_count
unsafe_shutdown_count
unused_rsvd_blk_cnt_tot
wear_leveling_count
workld_host_reads_perc
workld_media_wear_indic
workload_minutes
SMARTMONATTRS
)"
smartmon_attrs="$(echo "${smartmon_attrs}" | xargs | tr ' ' '|')"

parse_smartctl_attributes() {
    local disk="$1"
    local disk_type="$2"
    local labels="disk=\"${disk}\",type=\"${disk_type}\""
    sed 's/^ \+//g' |
        awk -v labels="${labels}" "${parse_smartctl_attributes_awk}" 2>/dev/null |
        tr '[:upper:]' '[:lower:]' |
        grep -E "(${smartmon_attrs})"
}

parse_smartctl_scsi_attributes() {
    local disk="$1"
    local disk_type="$2"
    local labels="disk=\"${disk}\",type=\"${disk_type}\""
    while read -r line; do
        attr_type="$(echo "${line}" | tr '=' ':' | cut -f1 -d: | sed 's/^ \+//g' | tr ' ' '_')"
        attr_value="$(echo "${line}" | tr '=' ':' | cut -f2 -d: | sed 's/^ \+//g')"
        case "${attr_type}" in
        number_of_hours_powered_up_) power_on="$(echo "${attr_value}" | awk '{ printf "%e\n", $1 }')" ;;
        Current_Drive_Temperature) temp_cel="$(echo "${attr_value}" | cut -f1 -d' ' | awk '{ printf "%e\n", $1 }')" ;;
        Blocks_sent_to_initiator_) lbas_read="$(echo "${attr_value}" | awk '{ printf "%e\n", $1 }')" ;;
        Blocks_received_from_initiator_) lbas_written="$(echo "${attr_value}" | awk '{ printf "%e\n", $1 }')" ;;
        Accumulated_start-stop_cycles) power_cycle="$(echo "${attr_value}" | awk '{ printf "%e\n", $1 }')" ;;
        Elements_in_grown_defect_list) grown_defects="$(echo "${attr_value}" | awk '{ printf "%e\n", $1 }')" ;;
        esac
    done
    [ -n "$power_on" ] && echo "power_on_hours_raw_value{${labels},smart_id=\"9\"} ${power_on}"
    [ -n "$temp_cel" ] && echo "temperature_celsius_raw_value{${labels},smart_id=\"194\"} ${temp_cel}"
    [ -n "$lbas_read" ] && echo "total_lbas_read_raw_value{${labels},smart_id=\"242\"} ${lbas_read}"
    [ -n "$lbas_written" ] && echo "total_lbas_written_raw_value{${labels},smart_id=\"241\"} ${lbas_written}"
    [ -n "$power_cycle" ] && echo "power_cycle_count_raw_value{${labels},smart_id=\"12\"} ${power_cycle}"
    [ -n "$grown_defects" ] && echo "grown_defects_count_raw_value{${labels},smart_id=\"-1\"} ${grown_defects}"
}

parse_smartctl_info() {
    local -i smart_available=0 smart_enabled=0 smart_healthy=
    local disk="$1" disk_type="$2"
    local model_family='' device_model='' serial_number='' fw_version='' vendor='' product='' revision='' lun_id=''
    while read -r line; do
        info_type="$(echo "${line}" | cut -f1 -d: | tr ' ' '_')"
        info_value="$(echo "${line}" | cut -f2- -d: | sed 's/^ \+//g' | sed 's/"/\\"/')"
        case "${info_type}" in
        Model_Family) model_family="${info_value}" ;;
        Device_Model) device_model="${info_value}" ;;
        Serial_Number|Serial_number) serial_number="${info_value}" ;;
        Firmware_Version) fw_version="${info_value}" ;;
        Vendor) vendor="${info_value}" ;;
        Product) product="${info_value}" ;;
        Revision) revision="${info_value}" ;;
        Logical_Unit_id) lun_id="${info_value}" ;;
        esac
        if [[ "${info_type}" == 'SMART_support_is' ]]; then
            case "${info_value:0:7}" in
            Enabled) smart_available=1; smart_enabled=1 ;;
            Availab) smart_available=1; smart_enabled=0 ;;
            Unavail) smart_available=0; smart_enabled=0 ;;
            esac
        fi
        if [[ "${info_type}" == 'SMART_overall-health_self-assessment_test_result' ]]; then
            case "${info_value:0:6}" in
            PASSED) smart_healthy=1 ;;
            *) smart_healthy=0 ;;
            esac
        elif [[ "${info_type}" == 'SMART_Health_Status' ]]; then
            case "${info_value:0:2}" in
            OK) smart_healthy=1 ;;
            *) smart_healthy=0 ;;
            esac
        fi
    done
    echo "device_info{disk=\"${disk}\",type=\"${disk_type}\",vendor=\"${vendor}\",product=\"${product}\",revision=\"${revision}\",lun_id=\"${lun_id}\",model_family=\"${model_family}\",device_model=\"${device_model}\",serial_number=\"${serial_number}\",firmware_version=\"${fw_version}\"} 1"
    echo "device_smart_available{disk=\"${disk}\",type=\"${disk_type}\"} ${smart_available}"
    echo "device_smart_enabled{disk=\"${disk}\",type=\"${disk_type}\"} ${smart_enabled}"
    [[ "${smart_healthy}" != "" ]] && echo "device_smart_healthy{disk=\"${disk}\",type=\"${disk_type}\"} ${smart_healthy}"
}

output_format_awk="$(
    cat <<'OUTPUTAWK'
BEGIN { v = "" }
v != $1 {
    print "# HELP smartmon_" $1 " SMART metric " $1;
    print "# TYPE smartmon_" $1 " gauge";
    v = $1
}
{print "smartmon_" $0}
OUTPUTAWK
)"

format_output() {
    sort |
        awk -F'{' "${output_format_awk}"
}

smartctl_version="$(/usr/sbin/smartctl -V | head -n1 | awk '$1 == "smartctl" {print $2}')"

echo "smartctl_version{version=\"${smartctl_version}\"} 1" | format_output

if [[ "$(expr "${smartctl_version}" : '\([0-9]*\)\..*')" -lt 6 ]]; then
    exit
fi

device_list="$(/usr/sbin/smartctl --scan-open | awk '/^\/dev/{print $1 "|" $3}')"

for device in ${device_list}; do
    disk="$(echo "${device}" | cut -f1 -d'|')"
    type="$(echo "${device}" | cut -f2 -d'|')"
    active=1
    echo "smartctl_run{disk=\"${disk}\",type=\"${type}\"}" "$(TZ=UTC date '+%s')"
    # Check if the device is in a low-power mode
    /usr/sbin/smartctl -n standby -d "${type}" "${disk}" > /dev/null || active=0
    echo "device_active{disk=\"${disk}\",type=\"${type}\"}" "${active}"
    # Skip further metrics to prevent the disk from spinning up
    test ${active} -eq 0 && continue
    # Get the SMART information and health
    /usr/sbin/smartctl -i -H -d "${type}" "${disk}" | parse_smartctl_info "${disk}" "${type}"
    # Get the SMART attributes
    case ${type} in
    sat) /usr/sbin/smartctl -A -d "${type}" "${disk}" | parse_smartctl_attributes "${disk}" "${type}" ;;
    sat+megaraid*) /usr/sbin/smartctl -A -d "${type}" "${disk}" | parse_smartctl_attributes "${disk}" "${type}" ;;
    scsi) /usr/sbin/smartctl -A -d "${type}" "${disk}" | parse_smartctl_scsi_attributes "${disk}" "${type}" ;;
    megaraid*) /usr/sbin/smartctl -A -d "${type}" "${disk}" | parse_smartctl_scsi_attributes "${disk}" "${type}" ;;
    nvme*) /usr/sbin/smartctl -A -d "${type}" "${disk}" | parse_smartctl_scsi_attributes "${disk}" "${type}" ;;
    usbprolific) /usr/sbin/smartctl -A -d "${type}" "${disk}" | parse_smartctl_attributes "${disk}" "${type}" ;;
    *)
            (>&2 echo "disk type is not sat, scsi, nvme or megaraid but ${type}")
        exit
        ;;
    esac
done | format_output
EOF
[ $? -ne 0 ] && log "Failed to create /usr/local/bin/smartmon.sh" "ERROR"

    chmod +x /usr/local/bin/smartmon.sh 2>> "${LOG_FILE}" || log "Failed to chmod /usr/local/bin/smartmon.sh" "ERROR"
    log "Setting up smart script for prometheus task"
    [ ! -d /var/lib/node_exporter/textfile_collector ] && mkdir -p /var/lib/node_exporter/textfile_collector
    echo "*/5 * * * * root /usr/local/bin/smartmon.sh > /var/lib/node_exporter/textfile_collector/smart_metrics.prom" >> /etc/crontab

    log "Setting up iTCO_wdt watchdog"
    echo "iTCO_wdt" > /etc/modules-load.d/10-watchdog.conf

    sensors-detect --auto | grep "no driver for ITE IT8613E" > /dev/null 2>&1
    if [ $? -eq 0 ]; then
        log "Setting up partial ITE 8613E support for NP0F6V2 hardware"
        echo "it87" > /etc/modules-load.d/20-it87.conf
        echo "options it87 force_id=0x8620" > /etc/modprobe.d/it87.conf
    fi
    log "Setting up tuned profiles"

    [ ! -d /etc/tuned/npf-eco ] && mkdir /etc/tuned/npf-eco
    [ ! -d /etc/tuned/npf-perf ]&& mkdir /etc/tuned/npf-perf

    cat << 'EOF' > /etc/tuned/npf-eco/tuned.conf
[main]
summary=NetPerfect Powersaver
include=powersave

# SETTINGS_VER 2023110301

[cpu]
# Use governor conservative whenever we can, if not, use powersave
governor=conserative
# The way we scale (set via cpupower set --perf-bias 0-15, 15 being most power efficient)
energy_perf_bias=15
# This will set the minimal frequency available (used with intel_pstate, which replaces cpufreq values
min_perf_pct=1
max_perf_pct=75

[sysctl]
# Never put 0, because of potentiel OOMs
vm.swappiness=1
# Keep watchguard active so our machine does not lay there for months without operating
# nmi_watchdog is enabled while we do not operate the tunnel so the machine does not stay dead
kernel.nmi_watchdog = 1

##### Prevent blocking system on high IO

#Percentage of system memory which when dirty then system can start writing data to the disks.
vm.dirty_background_ratio = 1

#Percentage of system memory which when dirty, the process doing writes would block and write out dirty pages to the disks.
vm.dirty_ratio = 2

# delay for disk commit
vm.dirty_writeback_centisecs = 100

[script]
# ON RHEL8, we need to keep profile dir
# ON RHEL9, relative path is enough
#script=\${i:PROFILE_DIR}/script.sh
script=script.sh
EOF
    [ $? -ne 0 ] && log "Failed to create /etc/tuned/npf-eco/tuned.conf" "ERROR"

    cat << 'EOF' > /etc/tuned/npf-perf/tuned.conf
[main]
summary=NetPerfect Performance
include=network-latency

# SETTINGS_VER 2023110301

[cpu]
# Use governor ondemand whenever we can, if not, use performance which will disable all frequency changes
governor=ondemand
# The way we scale (set via cpupower set --perf-bias 0-15, 15 being most powersave)
energy_perf_bias=performance
# This will set the minimal frequency available (used with intel_pstate, which replaces cpufreq values
min_perf_pct=40
max_perf_pct=100

[sysctl]
# Never put 0, because of potentiel OOMs
vm.swappiness=1
# Keep watchguard active so our machine does not lay there for months without operating
# let's keep the nmi_watchdog disabled while we operate the tunnel so we get no interruptions
kernel.nmi_watchdog = 0

##### Prevent blocking system on high IO

#Percentage of system memory which when dirty then system can start writing data to the disks.
vm.dirty_background_ratio = 1

#Percentage of system memory which when dirty, the process doing writes would block and write out dirty pages to the disks.
vm.dirty_ratio = 2

# delay for disk commit
vm.dirty_writeback_centisecs = 100

[script]
# ON RHEL8, we need to keep profile dir
# ON RHEL9, relative path is enough
#script=\${i:PROFILE_DIR}/script.sh
script=script.sh
EOF
    [ $? -ne 0 ] && log "Failed to create /etc/tuned/npf-perf/tuned.conf" "ERROR"

    cat << 'EOF' > /etc/tuned/npf-eco/script.sh
#!/usr/bin/env bash

SCRIPT_VER=2024040701

# Powersave will keep low frequency no matter what. If available, use conservative. If not use powersave
if cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors | grep conservative > /dev/null; then
	governor=conservative
else
	governor=powersave
fi

min_freq=$(cpupower frequency-info | grep limits | awk '{print $3}')
min_freq_unit=$(cpupower frequency-info | grep limits | awk '{print $4}')
max_freq=$(cpupower frequency-info | grep limits | awk '{print $6}')
max_freq_unit=$(cpupower frequency-info | grep limits | awk '{print $7}')

# Calc max freq in eco mode, don't use bc anymore since it's probably not installed
#max_freq_eco=$(bc <<< "scale=2; $max_freq/1.5")
max_freq_eco=$(echo "print(round(${max_freq}/1.8, 2))" | python3)

# Set governor, min and max freq
cpupower frequency-set -g $governor -d ${min_freq}${min_freq_unit} -u ${max_freq_eco}${max_freq_unit}

# Set perf bias to max eco
cpupower set --perf-bias 15

# Using idle states with a lacency > 10 will greatly affect bandwidth on KVM virtual machines
# Enable all idle states
cpupower idle-set -E
# Disable any higher than 50ns latency idle states
cpupower idle-set -D 50
EOF
    [ $? -ne 0 ] && log "Failed to create /etc/tuned/npf-eco/script.sh" "ERROR"

    cat << 'EOF' > /etc/tuned/npf-perf/script.sh
#!/usr/bin/env bash

SCRIPT_VER=2024040701

# Performance will keep CPU freq at max all the time. Prefer ondemand if available
if cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_available_governors | grep ondemand > /dev/null; then
	governor=ondemand
else
	governor=performance
fi

min_freq=$(cpupower frequency-info | grep limits | awk '{print $3}')
min_freq_unit=$(cpupower frequency-info | grep limits | awk '{print $4}')
max_freq=$(cpupower frequency-info | grep limits | awk '{print $6}')
max_freq_unit=$(cpupower frequency-info | grep limits | awk '{print $7}')

# Set governor, min and max freq
cpupower frequency-set -g $governor -d ${min_freq}${min_freq_unit} -u ${max_freq}${max_freq_unit}

# Set perf bias to max perf
cpupower set --perf-bias 0

# Using idle states with a lacency > 10 will greatly affect bandwidth on KVM virtual machines
# Enable all idle states
cpupower idle-set -E
# Disable any higher than 50ns latency idle states
cpupower idle-set -D 50
EOF
    [ $? -ne 0 ] && log "Failed to create /etc/tuned/npf-perf/script.sh" "ERROR"

    chmod +x /etc/tuned/{npf-eco,npf-perf}/script.sh 2>> "${LOG_FILE}" || log "Failed to chmod on tuned scripts" "ERROR"
else
    log "This is a virtual machine. We will not setup hardware tooling"
fi

# Configure serial console
log "Setting up serial console"
systemctl enable --now serial-getty@ttyS0.service 2>> "${LOG_FILE}" || log "Enabling serial getty failed" "ERROR"
sed -i 's/^GRUB_TERMINAL_OUTPUT="console"/GRUB_TERMINAL="serial console"\nGRUB_SERIAL_COMMAND="serial --unit=0 --word=8 --parity=no --speed 115200 --stop=1"/g' /etc/default/grub 2>> "${LOG_FILE}" || log "sed failed on /etc/default/grub" "ERROR"
# Update grub to add console
grubby --update-kernel=ALL --args="console=ttyS0,115200,n8 console=tty0" || log "Enabling serial getty failed" "ERROR"
grub2-mkconfig -o /boot/grub2/grub.cfg 2>> "${LOG_FILE}" || log "grub2-mkconfig failed" "ERROR"


# Setup automagic terminal resize
# singequotes on EOF prevents variable expansion
cat << 'EOF' >> /etc/profile.d/term_resize.sh
# Based on solution https://unix.stackexchange.com/a/283206/135459 that replaces xterm-resize package


resize_term() {

    old=$(stty -g)
    stty raw -echo min 0 time 5

    printf '\0337\033[r\033[999;999H\033[6n\0338' > /dev/tty
    IFS='[;R' read -r _ rows cols _ < /dev/tty

    stty "$old"

    # echo "cols:$cols"
    # echo "rows:$rows"
    stty cols "$cols" rows "$rows"
}

resize_term2() {

    old=$(stty -g)
    stty raw -echo min 0 time 5

    printf '\033[18t' > /dev/tty
    IFS=';t' read -r _ rows cols _ < /dev/tty

    stty "$old"

    # echo "cols:$cols"
    # echo "rows:$rows"
    stty cols "$cols" rows "$rows"
}

# Run only if we're in a serial terminal
[ $(tty) == /dev/ttyS0 ] && resize_term2
EOF
[ $? -ne 0 ] && log "Failed to create /etc/profile.d/term_resize.sh" "ERROR"

# Configure persistent journal
log "Setting up persistent boot journal"
[ ! -d /var/log/journal ] && mkdir /var/log/journal
systemd-tmpfiles --create --prefix /var/log/journal 2>> "${LOG_FILE}" || log "Failed to create systemd-tmpfiles" "ERROR"
sed -i 's/.*Storage=.*/Storage=persistent/g' /etc/systemd/journald.conf 2>> "${LOG_FILE}" || log "Failed to sed /etc/systemd/journald.conf" "ERROR"
killall -USR1 systemd-journald
# Configure max journal size
journalctl --vacuum-size=2G 2>> "${LOG_FILE}" || log "Failed to set journald vaccumsize" "ERROR"

log "Setup DNF automatic except for updates that require reboot"
systemctl disable dnf-makecache.timer 2>> "${LOG_FILE}" || log "Failed to disable dnf cache timer" "ERROR"
sed -i 's/^upgrade_type[[:space:]]*=[[:space:]].*/upgrade_type = security/g' /etc/dnf/automatic.conf 2>> "${LOG_FILE}" || log "Failed to sed /etc/dnf/automatic.conf" "ERROR"
sed -i 's/^download_updates[[:space:]]*=[[:space:]].*/download_updates = yes/g' /etc/dnf/automatic.conf 2>> "${LOG_FILE}" || log "Failed to sed /etc/dnf/automatic.conf" "ERROR"
sed -i 's/^apply_updates[[:space:]]*=[[:space:]].*/apply_updates = yes/g' /etc/dnf/automatic.conf 2>> "${LOG_FILE}" || log "Failed to sed /etc/dnf/automatic.conf" "ERROR"
sed -i 's/^emit_via[[:space:]]*=[[:space:]].*/emit_via = stdio/g' /etc/dnf/automatic.conf 2>> "${LOG_FILE}" || log "Failed to sed /etc/dnf/automatic.conf" "ERROR"
systemctl enable dnf-automatic.timer 2>> "${LOG_FILE}" || log "Failed to start dnf-automatic timer" "ERROR"

systemctl enable tuned 2>> "${LOG_FILE}" || log "Failed to start tuned" "ERROR"
# tuned-adm will complain that tuned is not running, but we cannot start tuned in install environment
# Hence, we will not log these errors. On reboot, the "good" profile will be selected anyway
if [ ${IS_VIRTUAL} != true ]; then
    log "Setting up hardware tuned profile"
    tuned-adm profile npf-eco
else
    log "Setting up virtual tuned profile"
    tuned-adm profile virtual-guest
fi

# Enable guest agent on KVM
if [ ${IS_VIRTUAL} == true ]; then
    log "Setting up Qemu guest agent"
    setsebool -P virt_qemu_ga_read_nonsecurity_files 1 2>> "${LOG_FILE}" || log "Failed to SELinux for qemu virtual machine" "ERROR"
	  systemctl enable qemu-guest-agent 2>> "${LOG_FILE}" || log "Failed to start qumu-guest-agent" "ERROR"
fi

# Prometheus support
check_internet
if [ $? -eq 0 ]; then
    log "Installing Node exporter"
    cd /opt || log "No /opt directory found"
    [ ! -d /var/lib/node_exporter/textfile_collector ] && mkdir -p /var/lib/node_exporter/textfile_collector
    curl -sSfL https://raw.githubusercontent.com/carlocorradini/node_exporter_installer/main/install.sh | INSTALL_NODE_EXPORTER_SKIP_FIREWALL=true INSTALL_NODE_EXPORTER_EXEC="--collector.logind --collector.interrupts --collector.systemd --collector.processes --collector.textfile.directory=/var/lib/node_exporter/textfile_collector" sh -s - 2>> "${LOG_FILE}" || log "Failed to setup node_exporter" "ERROR"
else
    log "No node_exporter installed" "ERROR"
fi

# Setting up watchdog in systemd
log "Setting up systemd watchdog"
sed -i -e 's,^#RuntimeWatchdogSec=.*,RuntimeWatchdogSec=60s,' /etc/systemd/system.conf 2>> "${LOG_FILE}" || log "Failed to sed /etc/systemd/system.conf" "ERROR"

log "Setup cake qdisc algorith and bbr congestion control"
echo net.core.default_qdisc=cake >> /etc/sysctl.d/99-sched.conf || log "Failed to write to /etc/sysctl.d/99-sched.conf" "ERROR"
echo net.ipv4.tcp_congestion_control=bbr >> /etc/sysctl.d/99-sched.conf || log "Failed to write to /etc/sysctl.d/99-sched.conf" "ERROR"

# Setting up banner
if [ "${POST_INSTALL_SCRIPT_GOOD}" != true ]; then
    MOTD_MSG="NPF POST SCRIPT: FAILURE"
else
    MOTD_MSG="NPF POST SCRIPT: SUCCESS"
fi
cat << EOF > /etc/motd
############################################################
# <<Un grand pouvoir implique de grandes responsabilités>> #
#                                                          #
#               !! Systeme en production !!                #
#               Toute modification doit être               #
#                inscrite dans le cahier de                #
#                 gestion des changements.                 #
#                                                          #
#       Toute connexion à ce système est journalisée       #
#                 ${MOTD_MSG}                 #
############################################################
EOF
[ $? -ne 0 ] && log "Failed to create /etc/motd" "ERROR"

# Cleanup kickstart file replaced with inst.nosave=all_ks
[ -f /root/anaconda-ks.cfg ] && /bin/shred -uz /root/anaconda-ks.cfg
[ -f /root/original-ks.cfg ] && /bin/shred -uz /root/original-ks.cfg

# Clean up log files, caches and temp
# Clear caches, files, and logs
/bin/rm -rf /tmp/* /tmp/.[a-zA-Z]* /var/tmp/*
/bin/rm -rf /etc/*- /etc/*.bak /etc/*~ /etc/sysconfig/*~
/bin/rm -rf /var/cache/dnf/* /var/cache/yum/* /var/log/rhsm/*
/bin/rm -rf /var/lib/dnf/* /var/lib/yum/repos/* /var/lib/yum/yumdb/*
/bin/rm -rf /var/lib/NetworkManager/* /var/lib/unbound/*.key
/bin/rm -rf /var/log/*debug /var/log/dmesg*
/bin/rm -rf /var/lib/cloud/* /var/log/cloud-init*.log
/bin/rm -rf /var/lib/authselect/backups/*
#/bin/rm -rf /var/log/anaconda

# Make sure we write everything to disk
sync; echo 3 > /proc/sys/vm/drop_caches

log "Finished at $(date) with state ${POST_INSTALL_SCRIPT_GOOD}"
%end

reboot --eject
